from crewai import Agent, Task, Crew
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import os
import requests
import re
from sheets_utils import (
    send_to_google_sheet, 
    get_existing_entries, 
    get_keywords_from_sheet, 
    generate_crew_prompt, 
    parse_crew_output,
    test_google_sheets_connection
)

# Charger les variables d'environnement (.env)
load_dotenv()

# Test de connexion Google Sheets au dÃ©marrage
print("ğŸ”§ VÃ©rification de la connexion Google Sheets...")
if not test_google_sheets_connection():
    print("âŒ Impossible de se connecter Ã  Google Sheets. VÃ©rifiez votre fichier credentials.json")
    exit(1)

# Initialiser le modÃ¨le LLM
llm = ChatOpenAI(model="gpt-4-turbo")

# GÃ©nÃ©rer dynamiquement le prompt basÃ© sur les colonnes du Google Sheet
prompt_text, expected_headers = generate_crew_prompt()
print(f"\nğŸ“‹ Colonnes Ã  rechercher : {expected_headers}\n")

# RÃ©cupÃ©rer les aides dÃ©jÃ  trouvÃ©es
existing_aides = get_existing_entries()

# Agent 1 : Recherche
research_agent = Agent(
    role="Chercheur d'aides au documentaire",
    goal="Identifier et extraire des aides financiÃ¨res pertinentes pour un documentaire en postproduction, abordant l'animisme et les esprits, tournÃ© en ThaÃ¯lande et coproduit avec la France.",
    backstory="Expert en financement culturel pour documentaires internationaux.",
    verbose=True,
    llm=llm
)

# Agent 2 : Nettoyeur
data_cleaning_agent = Agent(
    role="Nettoyeur de donnÃ©es",
    goal="Nettoyer et uniformiser les informations collectÃ©es pour crÃ©er une base exploitable, en respectant exactement les colonnes demandÃ©es.",
    backstory="SpÃ©cialiste de la normalisation de donnÃ©es pour des bases structurÃ©es.",
    verbose=True,
    llm=llm
)

# Agent 3 : VÃ©rificateur & Analyste
analysis_agent = Agent(
    role="VÃ©rificateur et analyste stratÃ©gique",
    goal="VÃ©rifier la pertinence des liens, s'assurer qu'ils pointent vers des aides spÃ©cifiques, et enrichir avec des commentaires stratÃ©giques.",
    backstory="Consultant expert en montage de dossiers de financement pour films internationaux.",
    verbose=True,
    llm=llm
)

# GÃ©nÃ©ration de la consigne en excluant les aides dÃ©jÃ  connues
exclusion_text = ""
if existing_aides:
    # Extraire les noms des aides existantes
    existing_names = []
    for aide in existing_aides:
        # Chercher le champ nom dans diffÃ©rentes variations possibles
        nom = aide.get('Nom') or aide.get('nom') or aide.get('NAME') or ""
        if nom:
            existing_names.append(nom)
    
    if existing_names:
        exclusion_text = "\nIgnore les aides dÃ©jÃ  listÃ©es avec les noms suivants :\n" + "\n".join(
            f"- {nom}" for nom in existing_names
        )

# API Google Search params
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_CX = os.getenv("GOOGLE_CSE_ID")  # Correction du nom de la variable

# Charger dynamiquement les mots-clÃ©s depuis Google Sheets (onglet "MotsClÃ©s")
keywords_to_test = get_keywords_from_sheet()

# Si pas de mots-clÃ©s dans le sheet, utiliser des mots-clÃ©s par dÃ©faut
if not keywords_to_test:
    print("âš ï¸ Aucun mot-clÃ© trouvÃ© dans l'onglet 'MotsClÃ©s'. Utilisation des mots-clÃ©s par dÃ©faut.")
    keywords_to_test = [
        "aide documentaire postproduction France",
        "financement documentaire coproduction internationale",
        "subvention documentaire culturel 2024"
    ]

print(f"\nğŸ” Mots-clÃ©s Ã  rechercher : {keywords_to_test}\n")

# API perso pour extraire le contenu des pages
CONTENT_API_KEY = os.getenv("VERIFYBOT_CONTENT_API_KEY")

def google_search_urls(query):
    """Effectue une recherche Google et retourne les URLs"""
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "key": GOOGLE_API_KEY,
        "cx": GOOGLE_CX,
        "q": query
    }
    try:
        res = requests.get(url, params=params)
        results = res.json()
        links = [item["link"] for item in results.get("items", [])][:5]  # Limiter Ã  5 rÃ©sultats
        print(f"\nğŸ” Recherche : {query}")
        for link in links:
            print(f"  - {link}")
        return links
    except Exception as e:
        print(f"âŒ Erreur recherche Google : {e}")
        return []

def get_page_content(target_url):
    """Extrait le contenu d'une page web"""
    api_url = f"https://cockpit.verifybot.app/api-get-content.php"
    params = {
        "url": target_url,
        "key": CONTENT_API_KEY
    }
    
    # Log de l'URL pour debug
    print(f"  ğŸ“¡ Appel API : {api_url}?url={target_url}&key={'*' * 10 if CONTENT_API_KEY else 'NO_KEY'}")
    
    try:
        response = requests.get(api_url, params=params, timeout=10)
        data = response.json()
        
        if response.status_code != 200:
            print(f"  âŒ Erreur HTTP {response.status_code}")
            return None
            
        content = data.get("content", "")
        if content:
            print(f"  âœ… Contenu extrait : {len(content)} caractÃ¨res")
        else:
            print(f"  âš ï¸ RÃ©ponse vide ou erreur : {data.get('error', 'Aucun contenu')}")
            
        return content if content else None
    except Exception as e:
        print(f"  âŒ Exception : {e}")
        return None

# Collecter le contenu des pages
documents_text = ""
total_urls = 0

for keyword in keywords_to_test:
    urls = google_search_urls(keyword)
    for url in urls:
        try:
            content = get_page_content(url)
            if content:
                documents_text += f"\n\n---\nContenu extrait de : {url}\n{content[:5000]}\n"  # Limiter la taille
                total_urls += 1
            else:
                print(f"âš ï¸ Aucun contenu extrait pour : {url}")
        except Exception as e:
            print(f"Erreur sur {url}: {e}")

print(f"\nğŸ“š Total : {total_urls} pages extraites\n")

# Si aucun contenu trouvÃ©, arrÃªter
if not documents_text:
    print("âŒ Aucun contenu trouvÃ©. VÃ©rifiez vos clÃ©s API.")
    exit(1)

# TÃ¢che de recherche avec prompt dynamique
funding_task = Task(
    description=f"""{prompt_text}
    
    IMPORTANT : Pour chaque aide trouvÃ©e, extrais TOUTES les informations demandÃ©es.
    Si une information n'est pas disponible, indique "Non spÃ©cifiÃ©" mais inclus quand mÃªme le champ.
    
    {exclusion_text}
    
    Contenu Ã  analyser :
    {documents_text[:50000]}""",  # Limiter la taille pour GPT
    expected_output=f"Une liste structurÃ©e d'aides avec EXACTEMENT ces champs : {', '.join(expected_headers)}",
    agent=research_agent
)

# TÃ¢che de nettoyage
data_cleaning_task = Task(
    description=f"""Prends les rÃ©sultats et nettoie-les pour un tableur :
    - Supprime TOUS les caractÃ¨res de formatage : *, **, _, __, #, ##, ###, etc.
    - Supprime les retours Ã  la ligne multiples et remplace par des espaces
    - Supprime les tabulations et caractÃ¨res spÃ©ciaux
    - Convertis tout en texte brut, sans formatage markdown ou HTML
    - Assure-toi que chaque aide a TOUS les champs suivants : {', '.join(expected_headers)}
    - Standardise les formats (dates en DD/MM/YYYY, emails sans espaces, liens complets avec https://)
    - Garde un format cohÃ©rent pour chaque entrÃ©e
    - Maximum 500 caractÃ¨res par champ pour Ã©viter les dÃ©bordements
    - Remplace les caractÃ¨res problÃ©matiques comme les guillemets par des apostrophes simples""",
    expected_output=f"Liste propre en texte brut avec ces champs exacts : {', '.join(expected_headers)}",
    agent=data_cleaning_agent
)

# TÃ¢che d'analyse
analysis_task = Task(
    description=f"""VÃ©rifie et enrichis chaque aide :
    - VÃ©rifie que les liens sont pertinents (pas de pages d'accueil gÃ©nÃ©riques)
    - Ajoute des commentaires stratÃ©giques sur l'adÃ©quation avec le projet
    - ComplÃ¨te les informations manquantes si possible
    - Structure finale avec TOUS ces champs : {', '.join(expected_headers)}""",
    expected_output=f"Version finale enrichie avec tous les champs : {', '.join(expected_headers)}",
    agent=analysis_agent
)

# CrÃ©ation de la crew
crew = Crew(
    agents=[research_agent, data_cleaning_agent, analysis_agent],
    tasks=[funding_task, data_cleaning_task, analysis_task],
    verbose=True
)

print("\nğŸš€ Lancement de la recherche d'aides...\n")

# ExÃ©cution
try:
    result = crew.kickoff()
    result_text = str(result)
    
    print("\nğŸ“„ RÃ©sultat brut (aperÃ§u) :")
    print(result_text[:1000] + "..." if len(result_text) > 1000 else result_text)
    
    # Parser le rÃ©sultat avec la nouvelle fonction dynamique
    entries = parse_crew_output(result_text, expected_headers)
    
    print(f"\nğŸ“Š {len(entries)} aide(s) extraite(s)")
    
    # Si pas d'entrÃ©es, essayer un parsing alternatif
    if not entries:
        print("\nâš ï¸ Parsing standard Ã©chouÃ©. Tentative de parsing alternatif...")
        
        # MÃ©thode alternative : chercher des blocs de texte structurÃ©s
        # Chercher toutes les URLs dans le texte
        urls = re.findall(r'https?://[^\s]+', result_text)
        print(f"URLs trouvÃ©es dans le rÃ©sultat : {len(urls)}")
        
        # CrÃ©er des entrÃ©es basiques avec ce qu'on trouve
        for i, url in enumerate(urls[:10]):  # Limiter Ã  10
            # Chercher du contexte autour de l'URL
            url_context = ""
            url_pos = result_text.find(url)
            if url_pos > 0:
                # Prendre 200 caractÃ¨res avant et aprÃ¨s l'URL
                start = max(0, url_pos - 200)
                end = min(len(result_text), url_pos + len(url) + 200)
                url_context = result_text[start:end]
            
            # Essayer d'extraire un nom
            nom_patterns = [
                r'(?:Nom|Aide|Programme|Fonds)\s*:\s*([^\n]+)',
                r'(?:^|\n)([A-Z][^:\n]{10,50})(?=\n)',
                r'(?:aide|subvention|financement)\s+([^\n]+)'
            ]
            
            nom = f"Aide {i+1}"  # Nom par dÃ©faut
            for pattern in nom_patterns:
                match = re.search(pattern, url_context, re.IGNORECASE)
                if match:
                    nom = match.group(1).strip()
                    break
            
            # CrÃ©er une entrÃ©e basique
            entry = {}
            
            # Remplir avec les colonnes attendues
            for header in expected_headers:
                if 'nom' in header.lower():
                    entry[header] = nom
                elif 'lien' in header.lower() or 'url' in header.lower():
                    entry[header] = url.strip()
                elif 'rÃ©sumÃ©' in header.lower() or 'resume' in header.lower():
                    entry[header] = url_context.replace('\n', ' ').strip()[:200]
                elif 'statut' in header.lower():
                    entry[header] = "Ã€ vÃ©rifier"
                elif 'organisme' in header.lower():
                    if 'cnc' in url.lower():
                        entry[header] = "CNC"
                    elif 'scam' in url.lower():
                        entry[header] = "SCAM"
                    elif 'iledefrance' in url.lower():
                        entry[header] = "RÃ©gion Ãle-de-France"
                    else:
                        entry[header] = ""
                elif 'pays' in header.lower():
                    if any(keyword in url.lower() for keyword in ['cnc', 'scam', 'iledefrance', 'france']):
                        entry[header] = "France"
                    else:
                        entry[header] = ""
                else:
                    entry[header] = ""
            
            entries.append(entry)
        
        print(f"\nğŸ“Š {len(entries)} aide(s) crÃ©Ã©e(s) par parsing alternatif")
    
    if entries:
        print("\nğŸ” AperÃ§u des entrÃ©es extraites :")
        for i, entry in enumerate(entries[:3]):
            print(f"\n--- EntrÃ©e {i+1} ---")
            for key, value in entry.items():
                print(f"  {key}: {value[:100] if value and len(str(value)) > 100 else value}")
        
        # Envoi vers Google Sheets
        print("\nğŸ“¤ Envoi vers Google Sheets...")
        send_to_google_sheet(entries)
    else:
        print("\nâŒ Aucune aide trouvÃ©e mÃªme avec le parsing alternatif")
        print("\nDÃ©but du rÃ©sultat brut pour analyse :")
        print(result_text[:1000])
        
except Exception as e:
    print(f"\nâŒ Erreur lors de l'exÃ©cution : {e}")
    import traceback
    traceback.print_exc()

#print("\nâœ… Script terminÃ©")

# Remplacer le dernier "print("\nâœ… Script terminÃ©")" par :

# Email de notification
try:
    from tools.smtp_email_tool import smtp_email_sender

    # PrÃ©parer le message
    if entries:
        subject = f"âœ… Funding Script - {len(entries)} nouvelles aides"
        message = f"Script terminÃ© avec succÃ¨s. {len(entries)} nouvelles aides ajoutÃ©es au Google Sheet."
    else:
        subject = "âš ï¸ Funding Script - Aucune nouvelle aide"
        message = "Script terminÃ© mais aucune nouvelle aide trouvÃ©e."

    # Ajouter timestamp
    # message += f"\nExÃ©cutÃ© le {datetime.now().strftime('%d/%m/%Y Ã  %H:%M')}"

    # Envoyer
    email_result = smtp_email_sender.invoke({
        "subject": subject,
        "content": message
    })
    print(f"\nğŸ“§ Email envoyÃ© : {email_result}")

except Exception as e:
    print(f"\nâš ï¸ Erreur envoi email : {e}")

print("\nâœ… Script terminÃ©")
